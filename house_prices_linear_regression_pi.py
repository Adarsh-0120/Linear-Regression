# -*- coding: utf-8 -*-
"""House-prices-linear-regression-PI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gFVM8hwlr3-WEXhqGrFpNyq5ZREdH_2-

Problem statement: implement a linear regression model to predict the prices of houses based on their square footage and the number of bedrooms and bathrooms

importing the required libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""loading the train and test datasets"""

df_train = pd.read_csv("train.csv")

df_test = pd.read_csv("test.csv")

print(df_train.shape)  #displays the total number of instances and features respectively

print(df_test.shape)

pd.set_option("display.max_columns", None)

pd.set_option("display.max_rows", None)

df_train.head()

df_test.head()

"""important features: BsmtFullBath, BsmtHalfBath, FullBath, HalfBath, BedroomAbvGr, KitchenAbvGr
* these are the features that are needed to predict the prices of houses using linear regression

Data integration : to clean both the train dataset and the test dataset in the same way so that it will give us a precise predicted output
"""

df = pd.concat([df_train,df_test])

print(df.shape)

df.head(5)

df.tail(5)

df.info()

df["Alley"].isnull().sum() #shows the number of null values present in this feature

df["Alley"].nunique()

df["Alley"].unique()

df["MSSubClass"].isnull().sum()

df["MSSubClass"].nunique()

df["MSSubClass"].unique()

df["MasVnrType"].isnull().sum()

"""* feature with high number of null values:
* Alley , MasVnrType , FirePlaceQu , PoolQC , Fence , MiscFeature
* they have to droped completely as it will cause uncertainity in the data, even if we think of replacing them with measures of central tendency it will result in false accuracy which will reult in the inefficiency of the whole system
"""

df.info()

"""* from here we get to know :     
1. we have 43 feature which are categorical , and 12 float , anf 26 integer features
2. so 38 are numerical or continuous
"""

int_features = df.select_dtypes(include = ["int64"]).columns
print("Total number of integer features: ",int_features.shape[0])
print("Integer features: ",int_features.tolist())

float_features = df.select_dtypes(include = ["float64"]).columns
print("Total number of float features: ",float_features.shape[0])
print("float features: ",float_features.tolist())

categorical_features = df.select_dtypes(include = ["object"]).columns
print("Total number of categorical features: ",categorical_features.shape[0])
print("categorical features: ",categorical_features.tolist())

df.describe()

"""#Data Visualization"""

plt.figure(figsize=(16,9)) #where the areas are white represents that they are null values
sns.heatmap(df.isnull())
plt.show()

df.isnull().sum()     # displays number of null values for each feature

null_p = df.isnull().sum()/df.shape[0]*100   #percentage of null values

"""* checking the features with missing to either drop them or not"""

#missing values = mv
#percent = p

mv_50_p = null_p[null_p > 50]
mv_50_p

mv_20_50_p = null_p[(null_p > 20) & (null_p < 51)]
mv_20_50_p

mv_5_20_p = null_p[(null_p > 5) & (null_p < 21)]
mv_5_20_p

"""* As per the domain knowledge the features mentioned here are not removable as they contribute to the cost of the houses
* So, we replace these null values with constant value 'NA' representing that these features are not present in that particular house

#Missing value imputation
"""

missing_value_features = null_p[null_p > 0]
missing_value_features

cat_missing_features = missing_value_features[missing_value_features.keys().isin(categorical_features)]
cat_missing_features

int_missing_features = missing_value_features[missing_value_features.keys().isin(int_features)]
int_missing_features

float_missing_features = missing_value_features[missing_value_features.keys().isin(float_features)]
float_missing_features

"""##**MSZoning**




> here we replaced the missing values with the mode value acc to the domain knowledge of the feature









"""

df["MSZoning"].value_counts()

sns.countplot(df["MSZoning"])

def oldNewCountPlot(df, df_new, feature):
  plt.figure(figsize=(12,6))
  plt.subplot(1,2,1)
  sns.countplot(df[feature])
  plt.subplot(1,2,2)
  sns.countplot(df_new[feature])

df["MSZoning"].mode()[0]

df_backup = df.copy()
df_backup.shape

mszoning_mode = df["MSZoning"].mode()[0]
df_backup["MSZoning"] = df_backup["MSZoning"].replace(np.nan, mszoning_mode)
df_backup["MSZoning"].isnull().sum()

oldNewCountPlot(df, df_backup, "MSZoning")

"""##**Alley**

> here we replace the missing values with 'NA' according to the domain knowledge


"""

df_backup["Alley"].isnull().sum()

sns.countplot(df_backup["Alley"])

df["Alley"].value_counts()

alley_missing = "NA"
df_backup["Alley"] = df_backup["Alley"].replace(np.nan, alley_missing)
df_backup["Alley"].isnull().sum()

oldNewCountPlot(df, df_backup, "Alley")

"""##**LotFrontage**

> here we replace the missing values with median according to the domain knowledge


"""

df_backup["LotFrontage"].describe()

df["LotFrontage"].median()

sns.distplot(df["LotFrontage"])
plt.show()

lotfrontage_median = df["LotFrontage"].median()
df_backup["LotFrontage"] = df_backup["LotFrontage"].replace(np.nan, lotfrontage_median)
df_backup["LotFrontage"].isnull().sum()

def oldNewBoxHistPlot(df, df_new, feature, figsize=(15,10)):
  plt.figure(figsize=figsize)
  plt.subplot(2,2,1)
  sns.boxplot(df[feature])
  plt.subplot(2,2,2)
  sns.boxplot(df_new[feature])
  plt.subplot(2,2,3)
  sns.distplot(df[feature])
  plt.subplot(2,2,4)
  sns.distplot(df_new[feature])

oldNewBoxHistPlot(df, df_backup, "LotFrontage")

df_backup["LotFrontage"].isnull().sum()

"""##**Utilities**

> we replace with the mode value


"""

df_backup["Utilities"].isnull().sum()

df_backup["Utilities"].mode()[0]

df_backup["Utilities"].value_counts()

utilities_mode = df["Utilities"].mode()[0]
df_backup["Utilities"] = df_backup["Utilities"].replace(np.nan,utilities_mode)
df_backup["Utilities"].isnull().sum()

df_backup["Utilities"].isnull().sum()

oldNewCountPlot(df, df_backup, "Utilities")

"""##**Exterior1st**"""

df["Exterior1st"].value_counts()

df["Exterior1st"].isnull().sum()

df["Exterior1st"].mode()[0]

exterior1st_missing = df["Exterior1st"].mode()[0]
df_backup["Exterior1st"] = df["Exterior1st"].replace(np.nan, exterior1st_missing)
df_backup["Exterior1st"].isnull().sum()

"""##**Exterior2nd**"""

exterior2nd_missing = df["Exterior2nd"].mode()[0]
df_backup["Exterior2nd"] = df["Exterior2nd"].replace(np.nan, exterior2nd_missing)
df_backup["Exterior2nd"].isnull().sum()

"""##**MasVnrType,MasVnrArea**"""

df["MasVnrType"].value_counts()

df["MasVnrType"].isnull().sum()

masvnrtype_missing = "None"
df_backup["MasVnrType"] = df["MasVnrType"].replace(np.nan, masvnrtype_missing)
df_backup["MasVnrType"].isnull().sum()

df_backup["MasVnrType"].value_counts()

df["MasVnrArea"].isnull().sum()

masvnrarea_missing = 0
df_backup["MasVnrArea"] = df["MasVnrArea"].replace(np.nan, masvnrarea_missing)
df_backup["MasVnrArea"].isnull().sum()

"""##**Basement**

* categorical:
1. BsmtQual	2.774923
2. BsmtCond	2.809181
3. BsmtExposure	2.809181
4. BsmtFinType1	2.706406
5. BsmtFinType2	2.740665

* numerical:
1. BsmtFinSF1	0.034258
2. BsmtFinSF2	0.034258
3. BsmtUnfSF	0.034258
4. TotalBsmtSF	0.034258
5. BsmtFullBath	0.068517
6. BsmtHalfBath	0.068517
"""

cat_bsmt_features = ["BsmtQual", "BsmtCond", "BsmtExposure", "BsmtFinType1", "BsmtFinType2"]
num_bsmt_features = ["BsmtFinSF1", "BsmtFinSF2", "BsmtUnfSF", "TotalBsmtSF", "BsmtFullBath", "BsmtHalfBath"]

sns.heatmap(df_backup[cat_bsmt_features].isnull())

for feat in cat_bsmt_features:
  print(f"Value counts of {feat}: {df[feat].value_counts()}")

bsmt_const = "NA"
for feat in cat_bsmt_features:
  df_backup[feat].replace(np.nan, bsmt_const, inplace = True)

df_backup[cat_bsmt_features].isnull().sum()

sns.heatmap(df_backup[num_bsmt_features].isnull())

df_backup[num_bsmt_features].isnull().sum()

df_bsmt = df[cat_bsmt_features + num_bsmt_features]
df_bsmt[df_bsmt.isnull().any(axis=1)]

bsmt_num = 0
for feat in num_bsmt_features:
  df_backup[feat].replace(np.nan, bsmt_num, inplace = True)

df_backup[num_bsmt_features].isnull().sum()

"""##**Kitchen, Electrical**"""

df[df["KitchenQual"].isnull()]

df[df["Electrical"].isnull()]

df["Electrical"].isnull().sum()

df["KitchenQual"].isnull().sum()

electrical_missing = df["Electrical"].mode()[0]
df_backup["Electrical"] = df_backup["Electrical"].replace(np.nan, electrical_missing)
df_backup["Electrical"].isnull().sum()

kitchenqual_missing = df["KitchenQual"].mode()[0]
df_backup["KitchenQual"] = df_backup["KitchenQual"].replace(np.nan, kitchenqual_missing)
df_backup["KitchenQual"].isnull().sum()

"""##**Functional**"""

df["Functional"].isnull().sum()

df["Functional"].value_counts()

functional_missing = df["Functional"].mode()[0]
df_backup["Functional"] = df_backup["Functional"].replace(np.nan, functional_missing)
df_backup["Functional"].isnull().sum()

"""##**FireplaceQu**"""

df["FireplaceQu"].isnull().sum()

df["FireplaceQu"].value_counts()

fireplacequ_missing = "NA"
df_backup["FireplaceQu"] = df_backup["FireplaceQu"].replace(np.nan, fireplacequ_missing)
df_backup["FireplaceQu"].isnull().sum()

"""##**PoolQC**"""

df["PoolQC"].value_counts()

df["PoolQC"].isnull().sum()

poolqc_missing = "NA"
df_backup["PoolQC"] = df_backup["PoolQC"].replace(np.nan, poolqc_missing)
df_backup["PoolQC"].isnull().sum()

"""##**Fence**"""

df["Fence"].value_counts()

df["Fence"].isnull().sum()

fence_missing = "NA"
df_backup["Fence"] = df_backup["Fence"].replace(np.nan, fence_missing)
df_backup["Fence"].isnull().sum()

"""##**MiscFeature**"""

df["MiscFeature"].value_counts()

df["MiscFeature"].isnull().sum()

miscfeature_missing = "NA"
df_backup["MiscFeature"] = df_backup["MiscFeature"].replace(np.nan, miscfeature_missing)
df_backup["MiscFeature"].isnull().sum()

"""##**SaleType**"""

df["SaleType"].isnull().sum()

df["SaleType"].value_counts()

saletype_missing = df["SaleType"].mode()[0]
df_backup["SaleType"] = df_backup["SaleType"].replace(np.nan, saletype_missing)
df_backup["SaleType"].isnull().sum()

"""##**Garage**

1. categorical :
* GarageType	5.378554
* GarageFinish	5.447071
* GarageQual	5.447071
* GarageCond	5.447071

2. numerical:
* GarageYrBlt	5.447071
* GarageCars	0.034258
* GarageArea	0.034258
"""

cat_grg_features = ["GarageType", "GarageFinish", "GarageQual", "GarageCond"]
num_grg_features = ["GarageYrBlt", "GarageCars", "GarageArea"]

garage_cont = "NA"
for feat in cat_grg_features:
  df_backup[feat] = df_backup[feat].replace(np.nan, garage_cont)

df_backup[cat_grg_features].isnull().sum()

num_grg_cont = 0
for feat in num_grg_features:
  df_backup[feat] = df_backup[feat].replace(np.nan, num_grg_cont)

df_backup[num_grg_features].isnull().sum()

df_backup.isnull().sum()

df_backup.isnull().any(axis=1).sum()

df_backup.head()

df_backup = df_backup.set_index("Id") #set index column as ID

df_backup.head()

plt.figure(figsize=(16,9)) #where the areas are white represents that they are null values
sns.heatmap(df_backup.isnull())
plt.show()

"""##**Feature Transformation**
* converting numerical feature to categorical feature
"""

num_conversion = ["MSSubClass", "YearBuilt", "YearRemodAdd", "GarageYrBlt", "MoSold", "YrSold"]

for feat in num_conversion:
  print(f"{feat}: data type = {df_backup[feat].dtype}")          #to check the data type of the features

df_backup[num_conversion].head()

import calendar
calendar.month_abbr[1]

df_backup["MoSold"] = df_backup['MoSold'].apply(lambda x: calendar.month_abbr[x])
df_backup["MoSold"].head()

for feat in num_conversion:
  df_backup[feat] = df_backup[feat].astype(str)

for feat in num_conversion:
  print(f"{feat}: data type = {df_backup[feat].dtype}")

"""##**Converting categorical features into numerical features**

Ordinal Encoding
"""

ordinal_end_var = ["ExterQual", "ExterCond", "BsmtQual", "BsmtCond", "BsmtExposure", "BsmtFinType1", "BsmtFinType2", "HeatingQC", "KitchenQual", "FireplaceQu", "GarageQual", "GarageCond", "PoolQC", "Functional", "GarageFinish", "PavedDrive", "Utilities"]

len(ordinal_end_var)

from pandas.api.types import CategoricalDtype    #python library to perform ordinal encoding

df_backup["ExterCond"] = df_backup["ExterCond"].astype(CategoricalDtype(categories = ["Po", "Fa", "TA", "Gd", "Ex"], ordered = True)).cat.codes

df_backup["ExterCond"].value_counts()

df_backup["BsmtQual"] = df_backup["BsmtQual"].astype(CategoricalDtype(categories = ["NA", "Po", "Fa", "TA", "Gd", "Ex"], ordered = True)).cat.codes

df_backup["BsmtQual"].value_counts()

df_backup["BsmtCond"] = df_backup["BsmtCond"].astype(CategoricalDtype(categories = ["NA", "Po", "Fa", "TA", "Gd", "Ex"], ordered = True)).cat.codes

df_backup["BsmtCond"].value_counts()

df_backup["ExterQual"].value_counts()

df_backup.head()

df_backup.head()

df_backup["ExterQual"].isnull().sum()

df_backup["ExterQual"].value_counts()

df_backup["ExterQual"] = df_backup["ExterQual"].astype(CategoricalDtype(categories = ["Po", "Fa", "TA", "Gd", "Ex"], ordered = True)).cat.codes

df_backup["ExterQual"].value_counts()

df_backup["BsmtExposure"] = df_backup["BsmtExposure"].astype(CategoricalDtype(categories = ["NA", "No", "Mn", "Av", "Gd"], ordered = True)).cat.codes

df_backup["BsmtExposure"].value_counts()

df_backup["BsmtFinType1"] = df_backup["BsmtFinType1"].astype(CategoricalDtype(categories = ["NA", "Unf", "LwQ", "Rec", "BLQ", "ALQ", "GLQ"], ordered = True)).cat.codes

df_backup["BsmtFinType1"].value_counts()

df_backup["BsmtFinType2"] = df_backup["BsmtFinType2"].astype(CategoricalDtype(categories = ["NA", "Unf", "LwQ", "Rec", "BLQ", "ALQ", "GLQ"], ordered = True)).cat.codes

df_backup["BsmtFinType2"].value_counts()

df_backup["HeatingQC"] = df_backup["HeatingQC"].astype(CategoricalDtype(categories = ["Po", "Fa", "TA", "Gd", "Ex"], ordered = True)).cat.codes

df_backup["HeatingQC"].value_counts()

df_backup["KitchenQual"] = df_backup["KitchenQual"].astype(CategoricalDtype(categories = ["Po", "Fa", "TA", "Gd", "Ex"], ordered = True)).cat.codes

df_backup["KitchenQual"].value_counts()

df_backup["FireplaceQu"] = df_backup["FireplaceQu"].astype(CategoricalDtype(categories = ["NA", "Po", "Fa", "TA", "Gd", "Ex"], ordered = True)).cat.codes

df_backup["FireplaceQu"].value_counts()

df_backup["GarageQual"] = df_backup["GarageQual"].astype(CategoricalDtype(categories = ["NA", "Po", "Fa", "TA", "Gd", "Ex"], ordered = True)).cat.codes

df_backup["GarageQual"].value_counts()  # dont know why we have got -1 here instead of 0 after encoding

df["GarageQual"].value_counts()

df_backup['GarageQual'] = df_backup['GarageQual'].replace(-1, 0)

df_backup["GarageQual"].value_counts()

""""GarageCond", "PoolQC", "Functional", "GarageFinish", "PavedDrive", "Utilities"
"""

df_backup["GarageCond"] = df_backup["GarageCond"].astype(CategoricalDtype(categories = ["NA", "Po", "Fa", "TA", "Gd", "Ex"], ordered = True)).cat.codes
df_backup["PoolQC"] = df_backup["PoolQC"].astype(CategoricalDtype(categories = ["NA", "Fa", "TA", "Gd", "Ex"], ordered = True)).cat.codes
df_backup["Functional"] = df_backup["Functional"].astype(CategoricalDtype(categories = ["Sal", "Sev", "Maj2", "Maj1", "Mod", "Min2", "Min1", "Typ"], ordered = True)).cat.codes
df_backup["GarageFinish"] = df_backup["GarageFinish"].astype(CategoricalDtype(categories = ["NA", "Unf", "RFn", "Fin"], ordered = True)).cat.codes
df_backup["PavedDrive"] = df_backup["PavedDrive"].astype(CategoricalDtype(categories = ["N", "P", "Y"], ordered = True)).cat.codes
df_backup["Utilities"] = df_backup["Utilities"].astype(CategoricalDtype(categories = ["ELO", "NoSeWa", "NoSewr", "AllPub"], ordered = True)).cat.codes

df_backup["GarageCond"].value_counts()

df_backup["PoolQC"].value_counts()

df_backup["Functional"].value_counts()

df_backup["GarageFinish"].value_counts()

df_backup["PavedDrive"].value_counts()

df_backup["Utilities"].value_counts()

"""#One hot encoding for nominal categorical data"""

df_backup.info()

df_encod = df_backup.copy()
object_features = df_encod.select_dtypes(include="object").columns.tolist()

len(object_features)

print(object_features)

df_encod.head(2)

df_encod.shape    # shape of the data before encoding

df_encod = pd.get_dummies(df_encod, columns = object_features, prefix = object_features, drop_first = True )

df_encod.shape    # shape of the data after encoding

df_encod.head(4)

df_encod.select_dtypes(include="object").columns.tolist()    # to see if there are any object features left, we can use .info() but it will be difficult to go through the whole 513 columns so we are using this to verify the number of object columns

df_encod.shape

"""#Linear Regression model"""

from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import pandas as pd

# Separate rows with and without SalePrice
df_train = df_encod[df_encod['SalePrice'].notnull()]
df_test = df_encod[df_encod['SalePrice'].isnull()]

# Define features (X) and target (y) for training
X_train = df_train.drop(columns=['SalePrice'])
y_train = df_train['SalePrice']

# Define features for testing
X_test = df_test.drop(columns=['SalePrice'])

# Feature scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Train the linear regression model
model = LinearRegression()
model.fit(X_train_scaled, y_train)
y_test_pred = model.predict(X_test_scaled)
df_test['SalePrice'] = y_test_pred
df_full = pd.concat([df_train, df_test], axis=0)
print("Predictions added to test set and dataset recombined.")

y_test_pred

df_encod.columns

"""#Final Output: Prediction of the prices of houses"""

# Creating an 'Id' column starting from 1460 up to 2919 (length of y_pred)
df_test['Id'] = range(1460, 1460 + len(df_test))
predictions_df = df_test[['Id', 'SalePrice']]
predictions_df.columns = ['Id', 'Predicted_SalePrice']

# Save the predictions to a new CSV file
predictions_df.to_csv('predictions.csv', index=False)